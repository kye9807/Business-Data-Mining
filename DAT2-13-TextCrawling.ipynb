{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup 활용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''\n",
    "<html> \n",
    "    <head>Test HTML</head> \n",
    "    <body> \n",
    "        <h1> Market  \n",
    "            <p id='fruits1' class='name' title=‘Banana’> Banana \n",
    "                <span class = 'price'> 3000 </span> \n",
    "                <span class = 'inventory'> 500 </span> \n",
    "                <span class = 'store'> CU </span> \n",
    "                <a href = 'http://test1'> url1 </a> \n",
    "            </p> \n",
    "            <p id='fruits2' class='name' title=‘Orange’> Orange \n",
    "                <span class = 'price'> 2000 </span> \n",
    "                <span class = 'inventory'> 100 </span> \n",
    "                <span class = 'store'> GS </span> \n",
    "                <a href = 'http://test2'> url2 </a> \n",
    "            </p> \n",
    "            <p id='fruits3' class='name' title=‘Pineapple’> Pineapple \n",
    "                <span class = 'price'> 5000 </span> \n",
    "                <span class = 'inventory'> 10 </span> \n",
    "                <span class = 'store'> CU </span> \n",
    "                <a href = 'http://test1'> url1 </a> \n",
    "            </p> \n",
    "        </h1> \n",
    "    </body> \n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"price\"> 3000 </span>,\n",
       " <span class=\"inventory\"> 500 </span>,\n",
       " <span class=\"store\"> CU </span>,\n",
       " <span class=\"price\"> 2000 </span>,\n",
       " <span class=\"inventory\"> 100 </span>,\n",
       " <span class=\"store\"> GS </span>,\n",
       " <span class=\"price\"> 5000 </span>,\n",
       " <span class=\"inventory\"> 10 </span>,\n",
       " <span class=\"store\"> CU </span>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"price\"> 3000 </span>,\n",
       " <span class=\"price\"> 2000 </span>,\n",
       " <span class=\"price\"> 5000 </span>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class name .\n",
    "soup.select('.price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"name\" id=\"fruits2\" title=\"‘Orange’\"> Orange \n",
       "                 <span class=\"price\"> 2000 </span>\n",
       " <span class=\"inventory\"> 100 </span>\n",
       " <span class=\"store\"> GS </span>\n",
       " <a href=\"http://test2\"> url2 </a>\n",
       " </p>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id name #\n",
    "soup.select('#fruits2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"price\"> 3000 </span>,\n",
       " <span class=\"price\"> 2000 </span>,\n",
       " <span class=\"price\"> 5000 </span>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Structure\n",
    "soup.select('p.name > span.price')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3000 \n",
      " 2000 \n",
      " 5000 \n"
     ]
    }
   ],
   "source": [
    "# get text\n",
    "soup.select('p > span.price')[0].text  \n",
    "\n",
    "# get multiple texts\n",
    "prices = soup.select('p > span.price')\n",
    "for price in prices:        \n",
    "    print(price.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://test1\n",
      "http://test2\n",
      "http://test1\n"
     ]
    }
   ],
   "source": [
    "# get attrs\n",
    "soup.select('a')[0].attrs['href'] \n",
    "\n",
    "# get multiple attrs\n",
    "urls = soup.select('a')\n",
    "for url in urls:        \n",
    "    print(url.attrs['href']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"name\" id=\"fruits1\" title=\"‘Banana’\">\n",
      " Banana\n",
      " <span class=\"price\">\n",
      "  3000\n",
      " </span>\n",
      " <span class=\"inventory\">\n",
      "  500\n",
      " </span>\n",
      " <span class=\"store\">\n",
      "  CU\n",
      " </span>\n",
      " <a href=\"http://test1\">\n",
      "  url1\n",
      " </a>\n",
      "</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the first one with the info including tag, class, value\n",
    "soup2 = soup.find('p', {'class' : 'name'})\n",
    "print(soup2.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': [' 3000 ', ' 2000 ', ' 5000 ']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all \n",
    "lst = {'Text':[]}\n",
    "\n",
    "for el in soup.find_all('span', {'class' : 'price'}):\n",
    "    lst['Text'].append(el.getText())\n",
    "\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://test1\n",
      "http://test2\n",
      "http://test1\n"
     ]
    }
   ],
   "source": [
    "# find all attribute values\n",
    "for el in soup.find_all('a'):\n",
    "    print(el.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다음 영화 리뷰 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "from tqdm import *\n",
    "\n",
    "url = 'https://movie.daum.net/moviedb/grade?movieId=93252&type=netizen'\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "lst = {'Rating':[], 'Text':[]}\n",
    "\n",
    "for el in soup.find_all('em', {'class' : 'emph_grade'}):\n",
    "    lst['Rating'].append(el.getText())\n",
    "    \n",
    "for el in soup.find_all('p', {'class' : 'desc_review'}):\n",
    "    lst['Text'].append(el.getText())\n",
    "    \n",
    "df = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n                                           ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rating                                               Text\n",
       "0     10   \\n                                           ...\n",
       "1     10   \\n                                           ...\n",
       "2      7                                                 \\n\n",
       "3      0                                                 \\n\n",
       "4     10   \\n                                           ...\n",
       "5     10   \\n                                           ...\n",
       "6     10   \\n                                           ...\n",
       "7     10   \\n                                           ...\n",
       "8     10   \\n                                           ...\n",
       "9     10   \\n                                           ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n                                            마무리까지 완벽했다 그 전 인피니티워의 감동과 대적할만한 내 인생 히어로물 희대의 명작 중 하나!!\\n                                        '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 페이지 리뷰 및 평점 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 453/453 [01:43<00:00,  4.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "from tqdm import *\n",
    "\n",
    "url = 'https://movie.daum.net/moviedb/grade?movieId=93252&type=netizen'\n",
    "df = pd.DataFrame({'Rating':[], 'Text':[]})\n",
    "\n",
    "for i in tqdm(range(1,454)):\n",
    "\n",
    "    page = '&page=' + str(i)    \n",
    "    url_page = url + page\n",
    "    \n",
    "    with urllib.request.urlopen(url_page) as response:\n",
    "        html = response.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    lst = {'Rating':[], 'Text':[]}\n",
    "\n",
    "    for el in soup.find_all('em', {'class' : 'emph_grade'}):\n",
    "        lst['Rating'].append(el.getText())\n",
    "    \n",
    "    for el in soup.find_all('p', {'class' : 'desc_review'}):\n",
    "        lst['Text'].append(el.getText())\n",
    "    \n",
    "    df2 = pd.DataFrame(lst)\n",
    "    df = pd.concat([df,df2],ignore_index=True)\n",
    "\n",
    "df.to_csv('data/endgame.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 맨 마지막 페이지 번호를 파악하기 어려운 경우\n",
    "- 맨 마지막 페이지에는 10개이하의 리뷰가 있을 것임. 0~9개까지의 리뷰가 있을 것임.\n",
    "- 이에 착안하여 range에서는 무척 큰 숫자까지 for loop을 돌게하고, 수집된 리뷰가 10개 이하면 for loop를 멈추는 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://movie.daum.net/moviedb/grade?movieId=93252&type=netizen'\n",
    "df = pd.DataFrame({'Rating':[], 'Text':[]})\n",
    "\n",
    "for i in range(1,1000000):\n",
    "\n",
    "    page = '&page=' + str(i)    \n",
    "    url_page = url + page\n",
    "    \n",
    "    with urllib.request.urlopen(url_page) as response:\n",
    "        html = response.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    lst = {'Rating':[], 'Text':[]}\n",
    "\n",
    "    for el in soup.find_all('em', {'class' : 'emph_grade'}):\n",
    "        lst['Rating'].append(el.getText())\n",
    "    \n",
    "    for el in soup.find_all('p', {'class' : 'desc_review'}):\n",
    "        lst['Text'].append(el.getText())\n",
    "    \n",
    "    df2 = pd.DataFrame(lst)\n",
    "    df = pd.concat([df,df2],ignore_index=True)\n",
    "    \n",
    "    if (len(lst['Text']) < 10): break\n",
    "\n",
    "df.to_csv('data/endgame.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습문제 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York 한 호텔의 리뷰 수집\n",
    "# Trump International Hotel and Tower New York\n",
    "#https://www.tripadvisor.com/Hotel_Review-g60763-d93623-Reviews-Trump_International_Hotel_and_Tower_New_York-New_York_City_New_York.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집할 리뷰의 주소 \n",
    "original_url = \"https://www.tripadvisor.com/Hotel_Review-g60763-d93623-Reviews-Trump_International_Hotel_and_Tower_New_York-New_York_City_New_York.html\"\n",
    "\n",
    "# 호텔 리뷰 마지막 페이지 번호 확인\n",
    "with urllib.request.urlopen(original_url) as response:\n",
    "        html = response.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "pages = soup.select('div.pageNumbers')\n",
    "\n",
    "for page in pages:        \n",
    "    pageString = page.text\n",
    "    \n",
    "last = pageString.split('…')\n",
    "last_page = last[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "lst = {'Hotel':[], 'Date':[], 'Stars':[], 'Title':[], 'Text':[]}\n",
    "\n",
    "for i in tqdm(range(3)): # 3대신 last_page 를 입력하면 모든 리뷰를 수집함 \n",
    "    \n",
    "    url1 = original_url.split('Reviews-')[0]\n",
    "    url1 = url1 + 'Reviews-'\n",
    "    urlTemp = original_url.split('Reviews-')[1]\n",
    "    url3 = urlTemp.split('.')[0]\n",
    "    url4 = urlTemp.split('.')[1]\n",
    "    url4 = '.' + url4\n",
    "     \n",
    "    if(i == 0):\n",
    "        url = url1 + url3 + url4\n",
    "    else:\n",
    "        url2 = 'or' + str(i*5) + '-'\n",
    "        url = url1 + url2 + url3 + url4\n",
    "        \n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        html = response.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    for el_title in soup.select('div.glasR4aX'):\n",
    "        lst['Hotel'].append(url3)\n",
    "        lst['Title'].append(el_title.getText())\n",
    "    \n",
    "    for el_date in soup.select('div._2fxQ4TOx > span'):\n",
    "        lst['Date'].append(el_date.getText().split('review')[1])\n",
    "        \n",
    "    for el_stars in soup.select('div.nf9vGX55 > span'):\n",
    "        lst['Stars'].append(int(el_stars.attrs['class'][1].split('_')[1])/10)\n",
    "        \n",
    "    for el in soup.select('q.IRsGHoPm'):\n",
    "        lst['Text'].append(el.getText())\n",
    "        \n",
    "df = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel</th>\n",
       "      <th>Date</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Sep 2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Smelly</td>\n",
       "      <td>Musty mildew smell in all rooms. Got switched ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Feb 2020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Delightful stay</td>\n",
       "      <td>Truly enjoyed our stay at this wonderful hotel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Sep 2020</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This is a five-star hotel without any five-sta...</td>\n",
       "      <td>Both the check-in and check-out service was di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Aug 2020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Hope to come back soon!</td>\n",
       "      <td>I cannot find anything or anybody to find faul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Mar 2020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A Wonderful place to Stay for a short break</td>\n",
       "      <td>This place was exceptional, from the moment we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Mar 2020</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Service was terrible</td>\n",
       "      <td>The property was very nice but the view of cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Mar 2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>staff need training...lots of it</td>\n",
       "      <td>the entire staff is a bit rude, always in a ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Mar 2020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wow. Wasn’t expecting that level of service...</td>\n",
       "      <td>I’m a Marriott guy. Have been for 15 years of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Feb 2020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Luxurious</td>\n",
       "      <td>We loved our recent stay. The staff was awesom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Feb 2020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Fabulous hotel at a fabulous location with fab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Feb 2020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wonderful Stay</td>\n",
       "      <td>I was extremely satisfied with our room and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Feb 2020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4 days at Trump International Hotel in New York</td>\n",
       "      <td>Very friendly attentive staff. Room was except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Feb 2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Location location location</td>\n",
       "      <td>Great place to stay to stroll the park and wak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Feb 2020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Still A 5 Star Property but......</td>\n",
       "      <td>As NYC continues its downward spiral, all inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Trump_International_Hotel_and_Tower_New_York-N...</td>\n",
       "      <td>Feb 2020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great for business</td>\n",
       "      <td>Nice bathrooms, spacious rooms overall. Staff ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Hotel       Date  Stars  \\\n",
       "0   Trump_International_Hotel_and_Tower_New_York-N...   Sep 2020    2.0   \n",
       "1   Trump_International_Hotel_and_Tower_New_York-N...   Feb 2020    5.0   \n",
       "2   Trump_International_Hotel_and_Tower_New_York-N...   Sep 2020    3.0   \n",
       "3   Trump_International_Hotel_and_Tower_New_York-N...   Aug 2020    5.0   \n",
       "4   Trump_International_Hotel_and_Tower_New_York-N...   Mar 2020    5.0   \n",
       "5   Trump_International_Hotel_and_Tower_New_York-N...   Mar 2020    3.0   \n",
       "6   Trump_International_Hotel_and_Tower_New_York-N...   Mar 2020    2.0   \n",
       "7   Trump_International_Hotel_and_Tower_New_York-N...   Mar 2020    5.0   \n",
       "8   Trump_International_Hotel_and_Tower_New_York-N...   Feb 2020    5.0   \n",
       "9   Trump_International_Hotel_and_Tower_New_York-N...   Feb 2020    5.0   \n",
       "10  Trump_International_Hotel_and_Tower_New_York-N...   Feb 2020    5.0   \n",
       "11  Trump_International_Hotel_and_Tower_New_York-N...   Feb 2020    5.0   \n",
       "12  Trump_International_Hotel_and_Tower_New_York-N...   Feb 2020    4.0   \n",
       "13  Trump_International_Hotel_and_Tower_New_York-N...   Feb 2020    5.0   \n",
       "14  Trump_International_Hotel_and_Tower_New_York-N...   Feb 2020    5.0   \n",
       "\n",
       "                                                Title  \\\n",
       "0                                              Smelly   \n",
       "1                                     Delightful stay   \n",
       "2   This is a five-star hotel without any five-sta...   \n",
       "3                             Hope to come back soon!   \n",
       "4         A Wonderful place to Stay for a short break   \n",
       "5                                Service was terrible   \n",
       "6                    staff need training...lots of it   \n",
       "7      Wow. Wasn’t expecting that level of service...   \n",
       "8                                           Luxurious   \n",
       "9                                           Fabulous!   \n",
       "10                                     Wonderful Stay   \n",
       "11    4 days at Trump International Hotel in New York   \n",
       "12                         Location location location   \n",
       "13                  Still A 5 Star Property but......   \n",
       "14                                 Great for business   \n",
       "\n",
       "                                                 Text  \n",
       "0   Musty mildew smell in all rooms. Got switched ...  \n",
       "1   Truly enjoyed our stay at this wonderful hotel...  \n",
       "2   Both the check-in and check-out service was di...  \n",
       "3   I cannot find anything or anybody to find faul...  \n",
       "4   This place was exceptional, from the moment we...  \n",
       "5   The property was very nice but the view of cen...  \n",
       "6   the entire staff is a bit rude, always in a ba...  \n",
       "7   I’m a Marriott guy. Have been for 15 years of ...  \n",
       "8   We loved our recent stay. The staff was awesom...  \n",
       "9   Fabulous hotel at a fabulous location with fab...  \n",
       "10  I was extremely satisfied with our room and th...  \n",
       "11  Very friendly attentive staff. Room was except...  \n",
       "12  Great place to stay to stroll the park and wak...  \n",
       "13  As NYC continues its downward spiral, all inst...  \n",
       "14  Nice bathrooms, spacious rooms overall. Staff ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/Trump_Hotel_NY.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
